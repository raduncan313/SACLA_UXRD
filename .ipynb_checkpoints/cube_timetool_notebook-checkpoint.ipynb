{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SACLA Data Processing Notebook (with timetool)\n",
    "## Overview\n",
    "\n",
    "This notebook is intended for use during x-ray pump-probe experiments using the SACLA free-electron laser at the SPring-8 synchrotron facility. Time-dependent measurements are performed by recording the detector images and x-ray intensity monitor values on an event-by-event basis (where an event is a measurement corresponding to a single pump-probe pair) while varying the time delay between the pump (optical/infrared/etc.) and the x-ray probe. The code below applies several filters to the data, sorts the data into bins according to time delay, and saves the result in the directory `cube_dir` as H5 \"cube\" files with the following datasets:\n",
    "\n",
    "- `scan_var` : the value of the time delay corresponding to each bin\n",
    "- `imgs` : the sum of all detector images of events falling into each bin\n",
    "- `i0` : the sum of all x-ray intensity monitor values of events falling into each bin\n",
    "- `bin_counts` : the number of events falling into each bin\n",
    "\n",
    "The bin values in `scan_var` are determined by the variables `binval_min`, `binval_max`, and `num_bins`.\n",
    "\n",
    "The binned data is saved separately into \"on\" and \"off\" files according to whether the laser shutter was open or closed. For time scans this means that the experimental conditions for all events that get sorted into the \"off\" file are equivalent regardless of bin.\n",
    "\n",
    "A spectroencoding diagnostic \"timetool\" is used to correct for timing jitter between the pump and the probe. It saves timing corrections for each run on an event-by-event basis as `.csv` files in the directory specified by `tt_dir`. These timing corrections need to be converted into picoseconds with the conversion factor `pix_to_ps`. The code below should only be used for time scans. For non-time scans, or for time scans without timetool correction, the notebook `cube_no-timetool_notebook.ipynb` should be used instead.\n",
    "\n",
    "In the filtering step prior to binning, the following filters are applied:\n",
    "- `nan_filt` : filters out all events where either the timetool correction or intensity monitor values were `NaN`\n",
    "- `intens_filt` : filters out all events with intensity monitor values falling outside the range specified in `intens_thresh`\n",
    "- `in_csv` : filters out all events that are not included in the timetool correction `.csv` file.\n",
    "- `x_filt` : filters out all events with closed or invalid x-ray shutter status\n",
    "- `las_filt` : filters out all events with invalid pump shutter status\n",
    "\n",
    "The detector images must be subtracted by a \"dark\" background image of the detector before they are sorted into bins. These background files are created by acquiring detector images with both the pump and probe shutters closed and using the `make_bg.py` script to save the resulting data as an H5 file. `bg_num` denotes the run number corresponding to the background measurement, and `bg_dir` is the directory in which the background file is stored.\n",
    "\n",
    "Motor values, detector images, and intensity monitor values are obtained using SACLA's `dbpy` and `stpy` python modules. Motor values for the pump and timetool delay stages are reported in pulses, which need to be converted to picoseconds with the conversion factor `pos_to_ps`.\n",
    "\n",
    "A python script version of this code is provided in `cube_timetool.py`, which can be run at the command line or submitted to the cluster using `qsub`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "### Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DataAccessUserAPI_path = '/home/software/SACLA_tool/DataAccessUserAPI/latest/python/lib'\n",
    "SACLA_python_modules = '/home/software/opt/intel/oneapi/intelpython/python3.7/lib/python3.7/site-packages'\n",
    "\n",
    "if not DataAccessUserAPI_path in sys.path:\n",
    "    sys.path.insert(0, DataAccessUserAPI_path)\n",
    "if not SACLA_python_modules in sys.path:\n",
    "    sys.path.insert(0, SACLA_python_modules)\n",
    "\n",
    "import numpy as np\n",
    "import dbpy\n",
    "import stpy\n",
    "import h5py\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions (may need to change these):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "hi_tag = 202301\n",
    "bl = 3 # specify beamline\n",
    "run = 1293034 # Run number\n",
    "\n",
    "# Motor names and filter names -- before the experiment check that these are correct\n",
    "det_ID = 'MPCCD-1N0-M06-002'\n",
    "xon_name = 'xfel_bl_3_shutter_1_open_valid/status'\n",
    "xoff_name = 'xfel_bl_3_shutter_1_close_valid/status'\n",
    "lason_name = 'xfel_bl_3_lh1_shutter_1_open_valid/status'\n",
    "lasoff_name = 'xfel_bl_3_lh1_shutter_1_close_valid/status'\n",
    "delay_name = 'xfel_bl_3_st_2_motor_1/position'\n",
    "tt_delay_name = 'xfel_bl_3_st_1_motor_73/position'\n",
    "intens_6_name = 'xfel_bl_3_st_2_pd_user_6_fitting_peak/voltage'\n",
    "intens_7_name = 'xfel_bl_3_st_2_pd_user_7_fitting_peak/voltage'\n",
    "intens_name = intens_6_name\n",
    "\n",
    "cube_dir = '/work/raduncan/2023A8060_work/raduncan/cubes_post/' # Directory where cubes are saved\n",
    "tt_dir = '/work/raduncan/2023A8060_work/timingtool/data/' # Directory where timetool CSV files are saved\n",
    "\n",
    "# Background information\n",
    "bg_num = 1292973 # Run number of background scan\n",
    "bg_dir = '/work/raduncan/2023A8060_work/backgrounds/' # Directory where background files are saved\n",
    "\n",
    "# Conversion factors\n",
    "pos_to_ps = 0.006671 # Convert delay stage pulse values to picoseconds\n",
    "pix_to_ps = 0.0024431 # Convert timetool pixel values to picoseconds\n",
    "\n",
    "# Threshold values\n",
    "energy_thresh = 2100 # Energy threshold for pixels -- set all pixels below this value to zero\n",
    "intens_thresh = (-np.inf, np.inf) # Filter for i0 values\n",
    "\n",
    "# Binning parameters -- these need to be manually set for each run\n",
    "binval_min = 2\n",
    "binval_max = 10\n",
    "num_bins = 161\n",
    "t0 = -448.82488"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and bin the scan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "bin_delta = (binval_max - binval_min)/(num_bins - 1)\n",
    "scan_var = np.linspace(binval_min, binval_max, num_bins)\n",
    "\n",
    "print('Loading scan data...')\n",
    "\n",
    "# load non-detector data\n",
    "csvcontents = np.genfromtxt(tt_dir + str(run)  + '.csv', delimiter=',', skip_header=2)\n",
    "nptaglist_csv = csvcontents[:,0].astype('int')\n",
    "ttpix_csv = csvcontents[:,2]\n",
    "taglist_csv = tuple(map(int, nptaglist_csv.tolist()))\n",
    "taglist = dbpy.read_taglist_bydetid(bl, run, det_ID)\n",
    "nptaglist = np.array(taglist)\n",
    "num_shots = len(taglist)\n",
    "intens = np.array(dbpy.read_syncdatalist_float(intens_6_name, hi_tag, taglist)) + np.array(dbpy.read_syncdatalist_float(intens_7_name, hi_tag, taglist))\n",
    "ttpix = np.zeros(len(taglist))\n",
    "\n",
    "for ii,tag in enumerate(taglist):\n",
    "    if tag in taglist_csv:\n",
    "        ttpix[ii] = ttpix_csv[taglist_csv.index(tag)]\n",
    "ttps = ttpix*pix_to_ps\n",
    "\n",
    "lason = np.array(dbpy.read_syncdatalist_float(lason_name, hi_tag, taglist), dtype=bool)\n",
    "lasoff = np.array(dbpy.read_syncdatalist_float(lasoff_name, hi_tag, taglist), dtype=bool)\n",
    "xon = np.array(dbpy.read_syncdatalist_float(xon_name, hi_tag, taglist), dtype=bool)\n",
    "xoff = np.array(dbpy.read_syncdatalist_float(xoff_name, hi_tag, taglist), dtype=bool)\n",
    "tt_delay = np.array(dbpy.read_syncdatalist_float(tt_delay_name, hi_tag, taglist))*pos_to_ps\n",
    "delay = np.array(dbpy.read_syncdatalist_float(delay_name, hi_tag, taglist))*pos_to_ps - tt_delay - ttps - t0 + np.nanmean(ttps)\n",
    "\n",
    "# Create filters\n",
    "nan_filt = np.logical_and.reduce([np.logical_not(np.isnan(intens)), np.logical_not(np.isnan(ttps))])\n",
    "intens_filt = np.logical_and((intens > intens_thresh[0]), (intens < intens_thresh[-1]))\n",
    "in_csv = np.array([tag in taglist_csv for tag in taglist])\n",
    "x_filt = np.logical_and(xon, np.logical_not(xoff))\n",
    "las_filt = np.logical_or(np.logical_and(lason, np.logical_not(lasoff)), np.logical_and(lasoff, np.logical_not(lason)))\n",
    "tot_filt = np.logical_and.reduce([nan_filt, intens_filt, in_csv, x_filt, las_filt])\n",
    "\n",
    "# Apply filters\n",
    "intens = intens[tot_filt]\n",
    "ttps = ttps[tot_filt]\n",
    "nptaglist = nptaglist[tot_filt]\n",
    "taglist = tuple(map(int, nptaglist.tolist()))\n",
    "lason = lason[tot_filt]\n",
    "lasoff = lasoff[tot_filt]\n",
    "tt_delay = tt_delay[tot_filt]\n",
    "delay = delay[tot_filt]\n",
    "\n",
    "# Generate bin indices for events\n",
    "bin_inds = np.digitize(delay - bin_delta/2, scan_var, right=True)\n",
    "bin_inds[bin_inds > num_bins - 1] = num_bins - 1\n",
    "bin_inds[bin_inds < 0] = 0\n",
    "\n",
    "# Separate events into laser-on and laser-off\n",
    "on_tags = tuple(map(int, nptaglist[lason].tolist()))\n",
    "off_tags = tuple(map(int, nptaglist[lasoff].tolist()))\n",
    "intens_on = intens[lason]\n",
    "intens_off = intens[lasoff]\n",
    "delay_on = delay[lason]\n",
    "delay_off = delay[lasoff]\n",
    "bin_inds_on = bin_inds[lason]\n",
    "bin_inds_off = bin_inds[lasoff]\n",
    "\n",
    "# Initialize detector reading objects and cube fields\n",
    "reader = stpy.StorageReader(det_ID, bl, (run, run))\n",
    "buffer = stpy.StorageBuffer(reader)\n",
    "\n",
    "i0_on = np.zeros(num_bins)\n",
    "bin_counts_on = np.zeros(num_bins)\n",
    "\n",
    "i0_off = np.zeros(num_bins)\n",
    "bin_counts_off = np.zeros(num_bins)\n",
    "\n",
    "print(f'Delays ranging from {min(delay)} to {max(delay)} ps')\n",
    "print(f'Binning into {num_bins} bins from {binval_min} to {binval_max} ps')\n",
    "print(f'Bin delta is {bin_delta} ps')\n",
    "print(f'{num_shots} shots before filtering')\n",
    "print(f'{len(on_tags) + len(off_tags)} shots after filtering')\n",
    "print(f'{len(on_tags)} laser-on shots, {len(off_tags)} laser-off shots')\n",
    "\n",
    "print('\\nBinning laser-on shots...')\n",
    "for ii,tag in enumerate(on_tags):\n",
    "    reader.collect(buffer, tag)\n",
    "    img = buffer.read_det_data(0)\n",
    "    i0 = intens_on[ii]\n",
    "    \n",
    "    \n",
    "    if ii == 0:\n",
    "        imgs_on = np.zeros((num_bins, img.shape[0], img.shape[1]))\n",
    "        imgs_off = np.zeros((num_bins, img.shape[0], img.shape[1]))\n",
    "        \n",
    "        # Load background image\n",
    "        with h5py.File(bg_dir + f'run{bg_num:04d}_{det_ID}.h5', 'r') as f:\n",
    "            img_bg = f['img'][:]\n",
    "            count_bg = f['count'][()]\n",
    "        \n",
    "        img_bg /= count_bg\n",
    "        img_bg = np.reshape(img_bg, img.shape)        \n",
    "        \n",
    "    gain = np.copy(buffer.read_det_info(0)['mp_absgain'])\n",
    "    img -= img_bg\n",
    "    img *= gain\n",
    "    \n",
    "    jj = bin_inds_on[ii]\n",
    "    img[img < energy_thresh] = 0\n",
    "    imgs_on[jj,:,:] += img\n",
    "    i0_on[jj] += i0\n",
    "    bin_counts_on[jj] += 1\n",
    "    \n",
    "    if (ii%100 == 0) and (ii > 0):\n",
    "        print(f'Binned {ii} shots...')\n",
    "\n",
    "print('Done binning laser-on shots')\n",
    "\n",
    "print('\\nBinning laser-off shots...')\n",
    "for ii,tag in enumerate(off_tags):\n",
    "    reader.collect(buffer, tag)\n",
    "    img = buffer.read_det_data(0)\n",
    "    i0 = intens_off[ii]\n",
    "    \n",
    "    if ii == 0:\n",
    "        imgs_off = np.zeros((num_bins, img.shape[0], img.shape[1]))\n",
    "        if len(on_tags) == 0:\n",
    "            imgs_on = np.zeros((num_bins, img.shape[0], img.shape[1]))\n",
    "        \n",
    "        # Load background\n",
    "        with h5py.File(bg_dir + f'run{bg_num:04d}_{det_ID}.h5', 'r') as f:\n",
    "            img_bg = f['img'][:]\n",
    "            count_bg = f['count'][()]\n",
    "            \n",
    "        img_bg /= count_bg\n",
    "        img_bg = np.reshape(img_bg, img.shape)\n",
    "    \n",
    "    gain = np.copy(buffer.read_det_info(0)['mp_absgain'])\n",
    "    img -= img_bg\n",
    "    img *= gain\n",
    "    \n",
    "    jj = bin_inds_off[ii]\n",
    "    img[img < energy_thresh] = 0\n",
    "    imgs_off[jj,:,:] += img\n",
    "    i0_off[jj] += i0\n",
    "    bin_counts_off[jj] += 1\n",
    "    \n",
    "    if (ii%100 == 0) and (ii > 0):\n",
    "        print(f'Binned {ii} shots...')\n",
    "\n",
    "print('Done binning')\n",
    "end_time = time()\n",
    "print(f'Took {end_time - start_time} seconds to bin the run.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the binned data as H5 cubes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cube to hdf5\n",
    "cubename_on = f'run{run:04d}_on.h5'\n",
    "cubename_off = f'run{run:04d}_off.h5'\n",
    "with h5py.File(cube_dir + cubename_on, 'w') as f:\n",
    "    f.create_dataset('scan_var', data=scan_var)\n",
    "    f.create_dataset('imgs', data=imgs_on)\n",
    "    f.create_dataset('i0', data=i0_on)\n",
    "    f.create_dataset('bin_counts', data=bin_counts_on)\n",
    "\n",
    "with h5py.File(cube_dir + cubename_off, 'w') as f:\n",
    "    f.create_dataset('scan_var', data=scan_var)\n",
    "    f.create_dataset('imgs', data=imgs_off)\n",
    "    f.create_dataset('i0', data=i0_off)\n",
    "    f.create_dataset('bin_counts', data=bin_counts_off)\n",
    "\n",
    "print(f'Saved cubes for run {run} in {cube_dir}')\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
